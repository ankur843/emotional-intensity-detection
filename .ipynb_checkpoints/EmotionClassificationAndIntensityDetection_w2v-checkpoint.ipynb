{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "      <td>False</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>True</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>False</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>False</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>False</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3955</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.833</td>\n",
       "      <td>False</td>\n",
       "      <td>Common app just randomly logged me out as I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3956</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.688</td>\n",
       "      <td>False</td>\n",
       "      <td>I'd rather laugh with the rarest genius, in be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3957</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "      <td>False</td>\n",
       "      <td>If you #invest in my new #film I will stop ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3958</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.333</td>\n",
       "      <td>False</td>\n",
       "      <td>Just watched Django Unchained, Other people ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3959</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.708</td>\n",
       "      <td>False</td>\n",
       "      <td>@KeithOlbermann depressing how despicable Trum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion  intensity  is_valid  \\\n",
       "0       anger      0.938     False   \n",
       "1       anger      0.896      True   \n",
       "2       anger      0.896     False   \n",
       "3       anger      0.896     False   \n",
       "4       anger      0.896     False   \n",
       "...       ...        ...       ...   \n",
       "3955  sadness      0.833     False   \n",
       "3956  sadness      0.688     False   \n",
       "3957  sadness      0.458     False   \n",
       "3958  sadness      0.333     False   \n",
       "3959  sadness      0.708     False   \n",
       "\n",
       "                                                   text  \n",
       "0     How the fu*k! Who the heck! moved my fridge!.....  \n",
       "1     So my Indian Uber driver just called someone t...  \n",
       "2     @DPD_UK I asked for my parcel to be delivered ...  \n",
       "3     so ef whichever butt wipe pulled the fire alar...  \n",
       "4     Don't join @BTCare they put the phone down on ...  \n",
       "...                                                 ...  \n",
       "3955  Common app just randomly logged me out as I wa...  \n",
       "3956  I'd rather laugh with the rarest genius, in be...  \n",
       "3957  If you #invest in my new #film I will stop ask...  \n",
       "3958  Just watched Django Unchained, Other people ma...  \n",
       "3959  @KeithOlbermann depressing how despicable Trum...  \n",
       "\n",
       "[3960 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/output/emotions_df.csv\")\n",
    "df = df[df.columns.difference(['Unnamed: 0','id'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3169\n",
       "True      791\n",
       "Name: is_valid, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_valid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =['i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself',\n",
    "            'yourselves','he','him','his','himself','she','her','hers','herself','it','its','itself',\n",
    "            'they','them','their','theirs','themselves','what','which','who','whom','this','that',\n",
    "            'these','those','am','is','are','was','were','be','been','being','have','has','had',\n",
    "            'having','do','does','did','doing','a','an','the','and','but','if','or','because','as',\n",
    "            'until','while','of','at','by','for','with','about','against','between','into','through',\n",
    "            'during','before','after','above','below','to','from','up','down','in','out','on','off',\n",
    "            'over','under','again','further','then','once','here','there','when','where','why','how',\n",
    "            'all','any','both','each','few','more','most','other','some','such','no','nor','not',\n",
    "            'only','own','same','so','than','too','very','s','t','can','will','just','don','should',\n",
    "            'now','uses','use','using','used','one','also']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    reviews_tokens = []\n",
    "    for review in data:\n",
    "        review = review.lower() #Convert to lower-case words\n",
    "        raw_word_tokens = re.findall(r'(?:\\w+)', review,flags = re.UNICODE) #remove pontuaction\n",
    "        word_tokens = [w for w in raw_word_tokens if not w in stop_words] # do not add stop words\n",
    "        reviews_tokens.append(word_tokens)\n",
    "    return reviews_tokens #return all tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "      <td>False</td>\n",
       "      <td>[fu, k, heck, moved, fridge, knock, landlord, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>True</td>\n",
       "      <td>[indian, uber, driver, called, someone, n, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>False</td>\n",
       "      <td>[dpd_uk, asked, parcel, delivered, pick, store...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>False</td>\n",
       "      <td>[ef, whichever, butt, wipe, pulled, fire, alar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>False</td>\n",
       "      <td>[join, btcare, put, phone, talk, rude, taking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3955</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.833</td>\n",
       "      <td>False</td>\n",
       "      <td>[common, app, randomly, logged, writing, last,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3956</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.688</td>\n",
       "      <td>False</td>\n",
       "      <td>[d, rather, laugh, rarest, genius, beautiful, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3957</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "      <td>False</td>\n",
       "      <td>[invest, new, film, stop, asking, invest, new,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3958</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.333</td>\n",
       "      <td>False</td>\n",
       "      <td>[watched, django, unchained, people, may, frow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3959</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.708</td>\n",
       "      <td>False</td>\n",
       "      <td>[keitholbermann, depressing, despicable, trump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion  intensity  is_valid  \\\n",
       "0       anger      0.938     False   \n",
       "1       anger      0.896      True   \n",
       "2       anger      0.896     False   \n",
       "3       anger      0.896     False   \n",
       "4       anger      0.896     False   \n",
       "...       ...        ...       ...   \n",
       "3955  sadness      0.833     False   \n",
       "3956  sadness      0.688     False   \n",
       "3957  sadness      0.458     False   \n",
       "3958  sadness      0.333     False   \n",
       "3959  sadness      0.708     False   \n",
       "\n",
       "                                                   text  \n",
       "0     [fu, k, heck, moved, fridge, knock, landlord, ...  \n",
       "1     [indian, uber, driver, called, someone, n, wor...  \n",
       "2     [dpd_uk, asked, parcel, delivered, pick, store...  \n",
       "3     [ef, whichever, butt, wipe, pulled, fire, alar...  \n",
       "4     [join, btcare, put, phone, talk, rude, taking,...  \n",
       "...                                                 ...  \n",
       "3955  [common, app, randomly, logged, writing, last,...  \n",
       "3956  [d, rather, laugh, rarest, genius, beautiful, ...  \n",
       "3957  [invest, new, film, stop, asking, invest, new,...  \n",
       "3958  [watched, django, unchained, people, may, frow...  \n",
       "3959  [keitholbermann, depressing, despicable, trump...  \n",
       "\n",
       "[3960 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = preprocess(list(df['text']))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZheMin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X = list(df['text'])\n",
    "# let X be a list of tokenized texts (i.e. list of lists of tokens)\n",
    "model = gensim.models.Word2Vec(X, size=100)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X,word2vec):\n",
    "    dim = 100\n",
    "    return np.array([\n",
    "        np.mean([word2vec[w] for w in words if w in word2vec]\n",
    "                or [np.zeros(dim)], axis=0)\n",
    "        for words in X\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_transform(X,word2vec):\n",
    "    dim = 100\n",
    "    return np.array([\n",
    "        np.sum([word2vec[w] for w in words if w in word2vec]\n",
    "                or [np.zeros(dim)], axis=0)\n",
    "        for words in X\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: take mean of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df.loc[df['is_valid']==True]\n",
    "df_train=df.loc[df['is_valid']==False]\n",
    "x_train = transform(df_train['text'],w2v)\n",
    "x_test = transform(df_test['text'],w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(40, 20), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='sgd', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mean = MLPClassifier(solver='sgd', alpha=1e-5, learning_rate = 'adaptive',\n",
    "                     hidden_layer_sizes=(40, 20), random_state=1, max_iter = 2000)\n",
    "clf_mean.fit(x_train,df_train.emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score: 0.48176583493282155\n",
      "1.3739732849109119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZheMin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf_emo = clf_mean.predict(x_test)\n",
    "print(\"f1-score:\",f1_score(clf_emo, df_test.emotion,average='weighted'))\n",
    "print(clf_mean.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
